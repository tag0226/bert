{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Chapter8.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2571b546430f4750953ce85d3126b7b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f111e7fab2bd44409c99aff7f1736fbc",
              "IPY_MODEL_f70f5686acbd4e4ca980d3356cbccf3f",
              "IPY_MODEL_64427665c2e942b6bfe401578c7ae61b"
            ],
            "layout": "IPY_MODEL_039feeba26424be689d4a5787698ad1b"
          }
        },
        "f111e7fab2bd44409c99aff7f1736fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5c358203f6640c69afaa86dd61835b3",
            "placeholder": "​",
            "style": "IPY_MODEL_e402572bc077480985e0e09010dacd2d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f70f5686acbd4e4ca980d3356cbccf3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e749a0fc9a464e499a34fd3c4d44a6cc",
            "max": 120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e4ba91079a04f30b03ed2c9fdd8915e",
            "value": 120
          }
        },
        "64427665c2e942b6bfe401578c7ae61b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1944e4552dc42bda8074401dc46a123",
            "placeholder": "​",
            "style": "IPY_MODEL_cabc6620edc047c6bab8a6dbe596eeb8",
            "value": " 120/120 [00:00&lt;00:00, 3.15kB/s]"
          }
        },
        "039feeba26424be689d4a5787698ad1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5c358203f6640c69afaa86dd61835b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e402572bc077480985e0e09010dacd2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e749a0fc9a464e499a34fd3c4d44a6cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e4ba91079a04f30b03ed2c9fdd8915e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1944e4552dc42bda8074401dc46a123": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cabc6620edc047c6bab8a6dbe596eeb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31e7ee02ea11414ba00901eeaa357e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0babe54e1bda4033be630828e50f336a",
              "IPY_MODEL_cd611975eda2421eb81808a1a8657f28",
              "IPY_MODEL_61888d19839b451797e4daeaeb8a0f88"
            ],
            "layout": "IPY_MODEL_73e526a6289248df97f5e6f4ca5fcd8e"
          }
        },
        "0babe54e1bda4033be630828e50f336a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_445ba54ba7e04dd4b395becc3be5447e",
            "placeholder": "​",
            "style": "IPY_MODEL_d108f3a467d74887bf6decc5460f0649",
            "value": "vocab.txt: 100%"
          }
        },
        "cd611975eda2421eb81808a1a8657f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e53b4ac595734cb78b1f180681c6d61d",
            "max": 257706,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24f36bf3637c413188de63da293347da",
            "value": 257706
          }
        },
        "61888d19839b451797e4daeaeb8a0f88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86b25cd5346a45cd9b212823b77ee3c8",
            "placeholder": "​",
            "style": "IPY_MODEL_26b1cc8a90ec4b66a77096ff9d7c8045",
            "value": " 258k/258k [00:00&lt;00:00, 2.06MB/s]"
          }
        },
        "73e526a6289248df97f5e6f4ca5fcd8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "445ba54ba7e04dd4b395becc3be5447e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d108f3a467d74887bf6decc5460f0649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e53b4ac595734cb78b1f180681c6d61d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24f36bf3637c413188de63da293347da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86b25cd5346a45cd9b212823b77ee3c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26b1cc8a90ec4b66a77096ff9d7c8045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f5ff8ac7dff43969e3189b70f57be78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a6ce6d32bc4495f8ba9a91688dab8c9",
              "IPY_MODEL_9103ccaefd3a4d01b4258fe7cfa700d9",
              "IPY_MODEL_a8664030f51c4a9b89f64da587da8082"
            ],
            "layout": "IPY_MODEL_edba1591f6eb4f229dc4e6e97d8d1013"
          }
        },
        "2a6ce6d32bc4495f8ba9a91688dab8c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ca0f752e7744648aff366da9670afb7",
            "placeholder": "​",
            "style": "IPY_MODEL_c592c97b90ea41e9aba5238b01f55b7a",
            "value": "config.json: 100%"
          }
        },
        "9103ccaefd3a4d01b4258fe7cfa700d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3721dc0657a7413081476d9e68379104",
            "max": 479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b766ed9664f4aa6b8ffa2ca5904c816",
            "value": 479
          }
        },
        "a8664030f51c4a9b89f64da587da8082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a70267b2aca463eb8755a3ec915cabc",
            "placeholder": "​",
            "style": "IPY_MODEL_5bf1369572224cb288bb7d59fa36f79e",
            "value": " 479/479 [00:00&lt;00:00, 12.6kB/s]"
          }
        },
        "edba1591f6eb4f229dc4e6e97d8d1013": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ca0f752e7744648aff366da9670afb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c592c97b90ea41e9aba5238b01f55b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3721dc0657a7413081476d9e68379104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b766ed9664f4aa6b8ffa2ca5904c816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a70267b2aca463eb8755a3ec915cabc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bf1369572224cb288bb7d59fa36f79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "065547c031e04e61a0d737959fae33af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ac635962d724f0f9330bdb4aa8b12f7",
              "IPY_MODEL_428b08c930914bae9296339eb95dc545",
              "IPY_MODEL_0299e6ca4c204a42b1c1e490ce1660d7"
            ],
            "layout": "IPY_MODEL_8fdeffe4127342dc9b1e0e85b6aa8ff3"
          }
        },
        "4ac635962d724f0f9330bdb4aa8b12f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e7d62e8e6a3426a8aebb86c66c05233",
            "placeholder": "​",
            "style": "IPY_MODEL_1989b36f14a3495e9cbc286deb3e6a67",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "428b08c930914bae9296339eb95dc545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4daa0ffdc7240ca88e32792c5e49c25",
            "max": 445021143,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8da1addd15f2440e832dd5e9911a945a",
            "value": 445021143
          }
        },
        "0299e6ca4c204a42b1c1e490ce1660d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01d92001ff9e4014a58b77c54f2de7e9",
            "placeholder": "​",
            "style": "IPY_MODEL_2090ecf5b566441d959f359e6f006208",
            "value": " 445M/445M [00:06&lt;00:00, 208MB/s]"
          }
        },
        "8fdeffe4127342dc9b1e0e85b6aa8ff3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e7d62e8e6a3426a8aebb86c66c05233": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1989b36f14a3495e9cbc286deb3e6a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4daa0ffdc7240ca88e32792c5e49c25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8da1addd15f2440e832dd5e9911a945a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01d92001ff9e4014a58b77c54f2de7e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2090ecf5b566441d959f359e6f006208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON6jU-cos5E1"
      },
      "source": [
        "# 8章\n",
        "- 以下で実行するコードには確率的な処理が含まれていることがあり、コードの出力結果と本書に記載されている出力例が異なることがあります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6r9ATFJImOU",
        "outputId": "1b42f01c-1a9d-4b08-aab4-59149849cd4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 8-1\n",
        "!mkdir chap8\n",
        "%cd ./chap8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/chap8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hJ-pXOwXBzH",
        "outputId": "74fe3f74-4db7-477a-df50-1ecc32381b6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 8-2\n",
        "!pip install transformers fugashi ipadic pytorch_lightning unidic-lite"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Collecting fugashi\n",
            "  Downloading fugashi-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting ipadic\n",
            "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Downloading fugashi-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (671 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.7/671.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ipadic\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556704 sha256=270929b01c3449483df68de9e56baf1e33ef58ef5bb8f8c639fff466c3557ac2\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/ea/e3/2f6e0860a327daba3b030853fce4483ed37468bbf1101c59c3\n",
            "Successfully built ipadic\n",
            "Installing collected packages: ipadic, fugashi\n",
            "Successfully installed fugashi-1.4.0 ipadic-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch-lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHxG8Al8ClzH",
        "outputId": "f0b30df6-5a46-4f73-d909-642be7196989"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.6)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.10.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.12.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->pytorch-lightning) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n",
            "Downloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning\n",
            "Successfully installed lightning-utilities-0.11.9 pytorch-lightning-2.4.0 torchmetrics-1.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWsBlMRNhnnx"
      },
      "source": [
        "# 8-3\n",
        "import itertools\n",
        "import random\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertJapaneseTokenizer, BertForTokenClassification\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "# 日本語学習済みモデル\n",
        "MODEL_NAME = 'tohoku-nlp/bert-base-japanese-whole-word-masking'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilBB1q6zPvww",
        "outputId": "e1770659-10c9-4926-8e30-6ff81daa7c46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 8-4\n",
        "normalize = lambda s: unicodedata.normalize(\"NFKC\",s)\n",
        "print(f'ＴＡＧＵＣＨＩ -> {normalize(\"ＴＡＧＵＣＨＩ\")}' )  # 全角アルファベット\n",
        "print(f'taguchi -> {normalize(\"taguchi\")}' )        # 半角アルファベット\n",
        "print(f'０１２６ -> {normalize(\"０１２６\")}' )  # 全角数字\n",
        "print(f'0126 -> {normalize(\"0126\")}' )        # 半角数字\n",
        "print(f'タグチ -> {normalize(\"タグチ\")}' )  # 全角カタカナ\n",
        "print(f'ﾀｸﾞﾁ -> {normalize(\"ﾀｸﾞﾁ\")}' )        # 半角カタカナ"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ＴＡＧＵＣＨＩ -> TAGUCHI\n",
            "taguchi -> taguchi\n",
            "０１２６ -> 0126\n",
            "0126 -> 0126\n",
            "タグチ -> タグチ\n",
            "ﾀｸﾞﾁ -> タグチ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mecab-python3"
      ],
      "metadata": {
        "id": "JP0QlDaItfRD",
        "outputId": "73039fca-b24d-4438-8d4f-475a3b0de93a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mecab-python3\n",
            "  Downloading mecab_python3-1.0.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Downloading mecab_python3-1.0.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (581 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.7/581.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mecab-python3\n",
            "Successfully installed mecab-python3-1.0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import MeCab\n",
        "import ipadic\n",
        "\n",
        "tagger = MeCab.Tagger(ipadic.MECAB_ARGS) # ipadic を辞書に指定してインスタンス生成\n",
        "\n",
        "text1 = \"田口君は12月１６日、500円のモンブランを買った。\" # 解析対象のテキストを定義\n",
        "\n",
        "text2 = \"たぐち君は１２月16日、５００円のﾓﾝﾌﾞﾗんを買った。\" # 解析対象のテキストを定義\n",
        "\n",
        "parsed_text1 = tagger.parse(text1) # 解析を実行\n",
        "parsed_text2 = tagger.parse(text2) # 解析を実行\n",
        "print(parsed_text1) # 解析結果を表示\n",
        "print(parsed_text2) # 解析結果を表示"
      ],
      "metadata": {
        "id": "H8n1te5ZtY4E",
        "outputId": "dd24f544-ac20-4c32-b30f-5a436f6f4f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'MeCab'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-95185d8ebbe2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mMeCab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mipadic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMeCab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mipadic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMECAB_ARGS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ipadic を辞書に指定してインスタンス生成\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'MeCab'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnK2OiMKhmt0"
      },
      "source": [
        "# 8-5\n",
        "class NER_tokenizer(BertJapaneseTokenizer):\n",
        "\n",
        "    def encode_plus_tagged(self, text, entities, max_length):\n",
        "        \"\"\"\n",
        "        文章とそれに含まれる固有表現が与えられた時に、\n",
        "        符号化とラベル列の作成を行う。\n",
        "        \"\"\"\n",
        "        # 固有表現の前後でtextを分割し、それぞれのラベルをつけておく。\n",
        "        entities = sorted(entities, key=lambda x: x['span'][0])\n",
        "        splitted = [] # 分割後の文字列を追加していく\n",
        "        position = 0\n",
        "        for entity in entities:\n",
        "            start = entity['span'][0]\n",
        "            end = entity['span'][1]\n",
        "            label = entity['type_id']\n",
        "            # 固有表現ではないものには0のラベルを付与\n",
        "            splitted.append({'text':text[position:start], 'label':0})\n",
        "            # 固有表現には、固有表現のタイプに対応するIDをラベルとして付与\n",
        "            splitted.append({'text':text[start:end], 'label':label})\n",
        "            position = end\n",
        "        splitted.append({'text': text[position:], 'label':0})\n",
        "        splitted = [ s for s in splitted if s['text'] ] # 長さ0の文字列は除く\n",
        "\n",
        "        # 分割されたそれぞれの文字列をトークン化し、ラベルをつける。\n",
        "        tokens = [] # トークンを追加していく\n",
        "        labels = [] # トークンのラベルを追加していく\n",
        "        for text_splitted in splitted:\n",
        "            text = text_splitted['text']\n",
        "            label = text_splitted['label']\n",
        "            tokens_splitted = self.tokenize(text)\n",
        "            labels_splitted = [label] * len(tokens_splitted)\n",
        "            tokens.extend(tokens_splitted)\n",
        "            labels.extend(labels_splitted)\n",
        "\n",
        "        # 符号化を行いBERTに入力できる形式にする。\n",
        "        input_ids = self.convert_tokens_to_ids(tokens)\n",
        "        encoding = self.prepare_for_model(\n",
        "            input_ids,\n",
        "            max_length=max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True\n",
        "        ) # input_idsをencodingに変換\n",
        "        # 特殊トークン[CLS]、[SEP]のラベルを0にする。\n",
        "        labels = [0] + labels[:max_length-2] + [0]\n",
        "        # 特殊トークン[PAD]のラベルを0にする。\n",
        "        labels = labels + [0]*( max_length - len(labels) )\n",
        "        encoding['labels'] = labels\n",
        "\n",
        "        return encoding\n",
        "\n",
        "    def encode_plus_untagged(\n",
        "        self, text, max_length=None, return_tensors=None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        文章をトークン化し、それぞれのトークンの文章中の位置も特定しておく。\n",
        "        \"\"\"\n",
        "        # 文章のトークン化を行い、\n",
        "        # それぞれのトークンと文章中の文字列を対応づける。\n",
        "        tokens = [] # トークンを追加していく。\n",
        "        tokens_original = [] # トークンに対応する文章中の文字列を追加していく。\n",
        "        words = self.word_tokenizer.tokenize(text) # MeCabで単語に分割\n",
        "        for word in words:\n",
        "            # 単語をサブワードに分割\n",
        "            tokens_word = self.subword_tokenizer.tokenize(word)\n",
        "            tokens.extend(tokens_word)\n",
        "            if tokens_word[0] == '[UNK]': # 未知語への対応\n",
        "                tokens_original.append(word)\n",
        "            else:\n",
        "                tokens_original.extend([\n",
        "                    token.replace('##','') for token in tokens_word\n",
        "                ])\n",
        "\n",
        "        # 各トークンの文章中での位置を調べる。（空白の位置を考慮する）\n",
        "        position = 0\n",
        "        spans = [] # トークンの位置を追加していく。\n",
        "        for token in tokens_original:\n",
        "            l = len(token)\n",
        "            while 1:\n",
        "                if token != text[position:position+l]:\n",
        "                    position += 1\n",
        "                else:\n",
        "                    spans.append([position, position+l])\n",
        "                    position += l\n",
        "                    break\n",
        "\n",
        "        # 符号化を行いBERTに入力できる形式にする。\n",
        "        input_ids = self.convert_tokens_to_ids(tokens)\n",
        "        encoding = self.prepare_for_model(\n",
        "            input_ids,\n",
        "            max_length=max_length,\n",
        "            padding='max_length' if max_length else False,\n",
        "            truncation=True if max_length else False\n",
        "        )\n",
        "        sequence_length = len(encoding['input_ids'])\n",
        "        # 特殊トークン[CLS]に対するダミーのspanを追加。\n",
        "        spans = [[-1, -1]] + spans[:sequence_length-2]\n",
        "        # 特殊トークン[SEP]、[PAD]に対するダミーのspanを追加。\n",
        "        spans = spans + [[-1, -1]] * ( sequence_length - len(spans) )\n",
        "\n",
        "        # 必要に応じてtorch.Tensorにする。\n",
        "        if return_tensors == 'pt':\n",
        "            encoding = { k: torch.tensor([v]) for k, v in encoding.items() }\n",
        "\n",
        "        return encoding, spans\n",
        "\n",
        "    def convert_bert_output_to_entities(self, text, labels, spans):\n",
        "        \"\"\"\n",
        "        文章、ラベル列の予測値、各トークンの位置から固有表現を得る。\n",
        "        \"\"\"\n",
        "        # labels, spansから特殊トークンに対応する部分を取り除く\n",
        "        labels = [label for label, span in zip(labels, spans) if span[0] != -1]\n",
        "        spans = [span for span in spans if span[0] != -1]\n",
        "\n",
        "        # 同じラベルが連続するトークンをまとめて、固有表現を抽出する。\n",
        "        entities = []\n",
        "        for label, group \\\n",
        "            in itertools.groupby(enumerate(labels), key=lambda x: x[1]):\n",
        "\n",
        "            group = list(group)\n",
        "            start = spans[group[0][0]][0]\n",
        "            end = spans[group[-1][0]][1]\n",
        "\n",
        "            if label != 0: # ラベルが0以外ならば、新たな固有表現として追加。\n",
        "                entity = {\n",
        "                    \"name\": text[start:end],\n",
        "                    \"span\": [start, end],\n",
        "                    \"type_id\": label\n",
        "                }\n",
        "                entities.append(entity)\n",
        "\n",
        "        return entities"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "source": [
        "!pip install unidic-lite"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Qy-ws36crt90",
        "outputId": "20ba8f8c-d4f0-4a6e-8835-f9074352cd2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidic-lite\n",
            "  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: unidic-lite\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658818 sha256=da95c2a27498a193c155e9b399e5356f48b12a2178856d9210422371f270fd53\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/e8/68/f9ac36b8cc6c8b3c96888cd57434abed96595d444f42243853\n",
            "Successfully built unidic-lite\n",
            "Installing collected packages: unidic-lite\n",
            "Successfully installed unidic-lite-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh07iizk9Onf",
        "outputId": "95358f91-45f8-459b-b0f9-a22ef1c1032a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275,
          "referenced_widgets": [
            "2571b546430f4750953ce85d3126b7b3",
            "f111e7fab2bd44409c99aff7f1736fbc",
            "f70f5686acbd4e4ca980d3356cbccf3f",
            "64427665c2e942b6bfe401578c7ae61b",
            "039feeba26424be689d4a5787698ad1b",
            "f5c358203f6640c69afaa86dd61835b3",
            "e402572bc077480985e0e09010dacd2d",
            "e749a0fc9a464e499a34fd3c4d44a6cc",
            "3e4ba91079a04f30b03ed2c9fdd8915e",
            "b1944e4552dc42bda8074401dc46a123",
            "cabc6620edc047c6bab8a6dbe596eeb8",
            "31e7ee02ea11414ba00901eeaa357e6c",
            "0babe54e1bda4033be630828e50f336a",
            "cd611975eda2421eb81808a1a8657f28",
            "61888d19839b451797e4daeaeb8a0f88",
            "73e526a6289248df97f5e6f4ca5fcd8e",
            "445ba54ba7e04dd4b395becc3be5447e",
            "d108f3a467d74887bf6decc5460f0649",
            "e53b4ac595734cb78b1f180681c6d61d",
            "24f36bf3637c413188de63da293347da",
            "86b25cd5346a45cd9b212823b77ee3c8",
            "26b1cc8a90ec4b66a77096ff9d7c8045",
            "9f5ff8ac7dff43969e3189b70f57be78",
            "2a6ce6d32bc4495f8ba9a91688dab8c9",
            "9103ccaefd3a4d01b4258fe7cfa700d9",
            "a8664030f51c4a9b89f64da587da8082",
            "edba1591f6eb4f229dc4e6e97d8d1013",
            "2ca0f752e7744648aff366da9670afb7",
            "c592c97b90ea41e9aba5238b01f55b7a",
            "3721dc0657a7413081476d9e68379104",
            "2b766ed9664f4aa6b8ffa2ca5904c816",
            "8a70267b2aca463eb8755a3ec915cabc",
            "5bf1369572224cb288bb7d59fa36f79e"
          ]
        }
      },
      "source": [
        "# 8-6\n",
        "tokenizer = NER_tokenizer.from_pretrained(MODEL_NAME)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/120 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2571b546430f4750953ce85d3126b7b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/258k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31e7ee02ea11414ba00901eeaa357e6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/479 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f5ff8ac7dff43969e3189b70f57be78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertJapaneseTokenizer'. \n",
            "The class this function is called from is 'NER_tokenizer'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5704VNOVt8Yg",
        "outputId": "f6c160d5-f48d-44a4-8bcf-0091c7b159b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 8-7\n",
        "text = '昨日のみらい事務所との打ち合わせは順調だった。'\n",
        "entities = [\n",
        "    {'name': 'みらい事務所', 'span': [3,9], 'type_id': 1}\n",
        "]\n",
        "\n",
        "encoding = tokenizer.encode_plus_tagged(\n",
        "    text, entities, max_length=20\n",
        ")\n",
        "print(encoding)\n",
        "\n",
        "\n",
        "# 8-7\n",
        "text1 = ''\n",
        "entities = [\n",
        "    {'name': 'みらい事務所', 'span': [3,9], 'type_id': 1}\n",
        "]\n",
        "\n",
        "encoding = tokenizer.encode_plus_tagged(\n",
        "    text, entities, max_length=20\n",
        ")\n",
        "print(encoding)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [2, 10271, 28486, 5, 546, 3000, 1518, 233, 13, 5, 1878, 2682, 9, 10750, 308, 10, 8, 3, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], 'labels': [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "{'input_ids': [2, 10271, 28486, 5, 546, 3000, 1518, 233, 13, 5, 1878, 2682, 9, 10750, 308, 10, 8, 3, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], 'labels': [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDik0FRIL38J",
        "outputId": "e9362456-39da-4451-c997-50e3c6c6b0be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 8-8\n",
        "text = '騰訊の英語名はTencent Holdings Ltdである。'\n",
        "encoding, spans = tokenizer.encode_plus_untagged(\n",
        "    text, return_tensors='pt'\n",
        ")\n",
        "print('# encoding')\n",
        "print(encoding)\n",
        "print('# spans')\n",
        "print(spans)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# encoding\n",
            "{'input_ids': tensor([[    2,     1,     5,  1543,   125,     9,  6749, 28550,  2953, 28550,\n",
            "         28566, 21202, 28683, 14050, 12475,    12,    31,     8,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "# spans\n",
            "[[-1, -1], [0, 2], [2, 3], [3, 5], [5, 6], [6, 7], [7, 9], [9, 10], [10, 12], [12, 13], [13, 14], [15, 18], [18, 19], [19, 23], [24, 27], [27, 28], [28, 30], [30, 31], [-1, -1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHS30W_woM-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "937624eb-4026-4b62-c044-18acbeb91d2f"
      },
      "source": [
        "# 8-9\n",
        "labels_predicted = [0,1,1,0,0,0,0,1,1,1,1,1,1,1,1,1,0,0,0,0]\n",
        "entities = tokenizer.convert_bert_output_to_entities(\n",
        "    text, labels_predicted, spans\n",
        ")\n",
        "print(entities)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'name': '騰訊の', 'span': [0, 3], 'type_id': 1}, {'name': 'ncent Holdings Ltdで', 'span': [9, 28], 'type_id': 1}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo45M23hSL_-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159,
          "referenced_widgets": [
            "065547c031e04e61a0d737959fae33af",
            "4ac635962d724f0f9330bdb4aa8b12f7",
            "428b08c930914bae9296339eb95dc545",
            "0299e6ca4c204a42b1c1e490ce1660d7",
            "8fdeffe4127342dc9b1e0e85b6aa8ff3",
            "0e7d62e8e6a3426a8aebb86c66c05233",
            "1989b36f14a3495e9cbc286deb3e6a67",
            "d4daa0ffdc7240ca88e32792c5e49c25",
            "8da1addd15f2440e832dd5e9911a945a",
            "01d92001ff9e4014a58b77c54f2de7e9",
            "2090ecf5b566441d959f359e6f006208"
          ]
        },
        "outputId": "bcdb79b4-a790-42c8-ac85-76814b315dac"
      },
      "source": [
        "# 8-10\n",
        "tokenizer = NER_tokenizer.from_pretrained(MODEL_NAME)\n",
        "bert_tc = BertForTokenClassification.from_pretrained(\n",
        "    MODEL_NAME, num_labels=4\n",
        ")\n",
        "bert_tc = bert_tc.cuda()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertJapaneseTokenizer'. \n",
            "The class this function is called from is 'NER_tokenizer'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "065547c031e04e61a0d737959fae33af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at tohoku-nlp/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t344Ak2_0C2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3efcdbca-c778-447b-c3e8-bbf9cfb9f19e"
      },
      "source": [
        "# 8-11\n",
        "text = '田口さんは無印良品に就職した。'\n",
        "\n",
        "# 符号化を行い、各トークンの文章中での位置も特定しておく。\n",
        "encoding, spans = tokenizer.encode_plus_untagged(\n",
        "    text, return_tensors='pt'\n",
        ")\n",
        "encoding = { k: v.cuda() for k, v in encoding.items() }\n",
        "\n",
        "# BERTでトークン毎の分類スコアを出力し、スコアの最も高いラベルを予測値とする。\n",
        "with torch.no_grad():\n",
        "    output = bert_tc(**encoding)\n",
        "    scores = output.logits\n",
        "    labels_predicted = scores[0].argmax(-1).cpu().numpy().tolist()\n",
        "\n",
        "# ラベル列を固有表現に変換\n",
        "entities = tokenizer.convert_bert_output_to_entities(\n",
        "    text, labels_predicted, spans\n",
        ")\n",
        "print(entities)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'name': '田口', 'span': [0, 2], 'type_id': 3}, {'name': 'さん', 'span': [2, 4], 'type_id': 1}, {'name': '印', 'span': [6, 7], 'type_id': 3}, {'name': 'に', 'span': [9, 10], 'type_id': 3}, {'name': '就職', 'span': [10, 12], 'type_id': 1}, {'name': 'し', 'span': [12, 13], 'type_id': 3}, {'name': 'た。', 'span': [13, 15], 'type_id': 1}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmFZVpb208CK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25379186-49f8-4b22-df20-3fec68f6d770"
      },
      "source": [
        "# 8-12\n",
        "data = [\n",
        "    {\n",
        "        'text': '田口さんは無印良品に就職した。',\n",
        "        'entities': [\n",
        "            {'name': '田口', 'span': [0, 2], 'type_id': 2},\n",
        "            {'name': '無印良品', 'span': [5, 9], 'type_id': 1}\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        'text': '良品計画は新商品「無印の家」を販売する。',\n",
        "        'entities': [\n",
        "            {'name': '良品計画', 'span': [0, 4], 'type_id': 1},\n",
        "            {'name': '無印の家', 'span': [9, 13], 'type_id': 3}\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "# 各データを符号化し、データローダを作成する。\n",
        "max_length=32\n",
        "dataset_for_loader = []\n",
        "for sample in data:\n",
        "    text = sample['text']\n",
        "    entities = sample['entities']\n",
        "    encoding = tokenizer.encode_plus_tagged(\n",
        "        text, entities, max_length=max_length\n",
        "    )\n",
        "    encoding = { k: torch.tensor(v) for k, v in encoding.items() }\n",
        "    dataset_for_loader.append(encoding)\n",
        "dataloader = DataLoader(dataset_for_loader, batch_size=len(data))\n",
        "\n",
        "# ミニバッチを取り出し損失を得る。\n",
        "for batch in dataloader:\n",
        "    batch = { k: v.cuda() for k, v in batch.items() } # GPU\n",
        "    output = bert_tc(**batch) # BERTへ入力\n",
        "    loss = output.loss # 損失\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.4497, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-4aEmfGf9qT"
      },
      "source": [
        "# 8-13\n",
        "!git clone --branch v2.0 https://github.com/stockmarkteam/ner-wikipedia-dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpwR_RXZlX80"
      },
      "source": [
        "# 8-14\n",
        "# データのロード\n",
        "dataset = json.load(open('ner-wikipedia-dataset/ner.json','r'))\n",
        "\n",
        "# 固有表現のタイプとIDを対応付る辞書\n",
        "type_id_dict = {\n",
        "    \"人名\": 1,\n",
        "    \"法人名\": 2,\n",
        "    \"政治的組織名\": 3,\n",
        "    \"その他の組織名\": 4,\n",
        "    \"地名\": 5,\n",
        "    \"施設名\": 6,\n",
        "    \"製品名\": 7,\n",
        "    \"イベント名\": 8\n",
        "}\n",
        "\n",
        "# カテゴリーをラベルに変更、文字列の正規化する。\n",
        "for sample in dataset:\n",
        "    sample['text'] = unicodedata.normalize('NFKC', sample['text'])\n",
        "    for e in sample[\"entities\"]:\n",
        "        e['type_id'] = type_id_dict[e['type']]\n",
        "        del e['type']\n",
        "\n",
        "# データセットの分割\n",
        "random.shuffle(dataset)\n",
        "n = len(dataset)\n",
        "n_train = int(n*0.6)\n",
        "n_val = int(n*0.2)\n",
        "dataset_train = dataset[:n_train]\n",
        "dataset_val = dataset[n_train:n_train+n_val]\n",
        "dataset_test = dataset[n_train+n_val:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDGDvIPIlX-s"
      },
      "source": [
        "# 8-15\n",
        "def create_dataset(tokenizer, dataset, max_length):\n",
        "    \"\"\"\n",
        "    データセットをデータローダに入力できる形に整形。\n",
        "    \"\"\"\n",
        "    dataset_for_loader = []\n",
        "    for sample in dataset:\n",
        "        text = sample['text']\n",
        "        entities = sample['entities']\n",
        "        encoding = tokenizer.encode_plus_tagged(\n",
        "            text, entities, max_length=max_length\n",
        "        )\n",
        "        encoding = { k: torch.tensor(v) for k, v in encoding.items() }\n",
        "        dataset_for_loader.append(encoding)\n",
        "    return dataset_for_loader\n",
        "\n",
        "# トークナイザのロード\n",
        "tokenizer = NER_tokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# データセットの作成\n",
        "max_length = 128\n",
        "dataset_train_for_loader = create_dataset(\n",
        "    tokenizer, dataset_train, max_length\n",
        ")\n",
        "dataset_val_for_loader = create_dataset(\n",
        "    tokenizer, dataset_val, max_length\n",
        ")\n",
        "\n",
        "# データローダの作成\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train_for_loader, batch_size=32, shuffle=True\n",
        ")\n",
        "dataloader_val = DataLoader(dataset_val_for_loader, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "446u47Os_Arh"
      },
      "source": [
        "# 8-16\n",
        "# PyTorch Lightningのモデル\n",
        "class BertForTokenClassification_pl(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, model_name, num_labels, lr):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.bert_tc = BertForTokenClassification.from_pretrained(\n",
        "            model_name,\n",
        "            num_labels=num_labels\n",
        "        )\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        output = self.bert_tc(**batch)\n",
        "        loss = output.loss\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        output = self.bert_tc(**batch)\n",
        "        val_loss = output.loss\n",
        "        self.log('val_loss', val_loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
        "\n",
        "checkpoint = pl.callbacks.ModelCheckpoint(\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_top_k=1,\n",
        "    save_weights_only=True,\n",
        "    dirpath='model/'\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    gpus=1,\n",
        "    max_epochs=5,\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "\n",
        "# ファインチューニング\n",
        "model = BertForTokenClassification_pl(\n",
        "    MODEL_NAME, num_labels=9, lr=1e-5\n",
        ")\n",
        "trainer.fit(model, dataloader_train, dataloader_val)\n",
        "best_model_path = checkpoint.best_model_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OU3oPuxCEWz"
      },
      "source": [
        "# 8-17\n",
        "def predict(text, tokenizer, bert_tc):\n",
        "    \"\"\"\n",
        "    BERTで固有表現抽出を行うための関数。\n",
        "    \"\"\"\n",
        "    # 符号化\n",
        "    encoding, spans = tokenizer.encode_plus_untagged(\n",
        "        text, return_tensors='pt'\n",
        "    )\n",
        "    encoding = { k: v.cuda() for k, v in encoding.items() }\n",
        "\n",
        "    # ラベルの予測値の計算\n",
        "    with torch.no_grad():\n",
        "        output = bert_tc(**encoding)\n",
        "        scores = output.logits\n",
        "        labels_predicted = scores[0].argmax(-1).cpu().numpy().tolist()\n",
        "\n",
        "    # ラベル列を固有表現に変換\n",
        "    entities = tokenizer.convert_bert_output_to_entities(\n",
        "        text, labels_predicted, spans\n",
        "    )\n",
        "\n",
        "    return entities\n",
        "\n",
        "# トークナイザのロード\n",
        "tokenizer = NER_tokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# ファインチューニングしたモデルをロードし、GPUにのせる。\n",
        "model = BertForTokenClassification_pl.load_from_checkpoint(\n",
        "    best_model_path\n",
        ")\n",
        "bert_tc = model.bert_tc.cuda()\n",
        "\n",
        "# 固有表現抽出\n",
        "# 注：以下ではコードのわかりやすさのために、1データづつ処理しているが、\n",
        "# バッチ化して処理を行った方が処理時間は短い\n",
        "entities_list = [] # 正解の固有表現を追加していく。\n",
        "entities_predicted_list = [] # 抽出された固有表現を追加していく。\n",
        "for sample in tqdm(dataset_test):\n",
        "    text = sample['text']\n",
        "    entities_predicted = predict(text, tokenizer, bert_tc) # BERTで予測\n",
        "    entities_list.append(sample['entities'])\n",
        "    entities_predicted_list.append( entities_predicted )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-Fu6xJZ29HJ"
      },
      "source": [
        "# 8-18\n",
        "print(\"# 正解\")\n",
        "print(entities_list[0])\n",
        "print(\"# 抽出\")\n",
        "print(entities_predicted_list[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeZzmNigiDsD"
      },
      "source": [
        "# 8-19\n",
        "def evaluate_model(entities_list, entities_predicted_list, type_id=None):\n",
        "    \"\"\"\n",
        "    正解と予測を比較し、モデルの固有表現抽出の性能を評価する。\n",
        "    type_idがNoneのときは、全ての固有表現のタイプに対して評価する。\n",
        "    type_idが整数を指定すると、その固有表現のタイプのIDに対して評価を行う。\n",
        "    \"\"\"\n",
        "    num_entities = 0 # 固有表現(正解)の個数\n",
        "    num_predictions = 0 # BERTにより予測された固有表現の個数\n",
        "    num_correct = 0 # BERTにより予測のうち正解であった固有表現の数\n",
        "\n",
        "    # それぞれの文章で予測と正解を比較。\n",
        "    # 予測は文章中の位置とタイプIDが一致すれば正解とみなす。\n",
        "    for entities, entities_predicted \\\n",
        "        in zip(entities_list, entities_predicted_list):\n",
        "\n",
        "        if type_id:\n",
        "            entities = [ e for e in entities if e['type_id'] == type_id ]\n",
        "            entities_predicted = [\n",
        "                e for e in entities_predicted if e['type_id'] == type_id\n",
        "            ]\n",
        "\n",
        "        get_span_type = lambda e: (e['span'][0], e['span'][1], e['type_id'])\n",
        "        set_entities = set( get_span_type(e) for e in entities )\n",
        "        set_entities_predicted = \\\n",
        "            set( get_span_type(e) for e in entities_predicted )\n",
        "\n",
        "        num_entities += len(entities)\n",
        "        num_predictions += len(entities_predicted)\n",
        "        num_correct += len( set_entities & set_entities_predicted )\n",
        "\n",
        "    # 指標を計算\n",
        "    precision = num_correct/num_predictions # 適合率\n",
        "    recall = num_correct/num_entities # 再現率\n",
        "    f_value = 2*precision*recall/(precision+recall) # F値\n",
        "\n",
        "    result = {\n",
        "        'num_entities': num_entities,\n",
        "        'num_predictions': num_predictions,\n",
        "        'num_correct': num_correct,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f_value': f_value\n",
        "    }\n",
        "\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVbxf1FRlYBU"
      },
      "source": [
        "# 8-20\n",
        "print( evaluate_model(entities_list, entities_predicted_list) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD9sFRUu4Z4c"
      },
      "source": [
        "# 8-21\n",
        "class NER_tokenizer_BIO(BertJapaneseTokenizer):\n",
        "\n",
        "    # 初期化時に固有表現のカテゴリーの数`num_entity_type`を\n",
        "    # 受け入れるようにする。\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.num_entity_type = kwargs.pop('num_entity_type')\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def encode_plus_tagged(self, text, entities, max_length):\n",
        "        \"\"\"\n",
        "        文章とそれに含まれる固有表現が与えられた時に、\n",
        "        符号化とラベル列の作成を行う。\n",
        "        \"\"\"\n",
        "        # 固有表現の前後でtextを分割し、それぞれのラベルをつけておく。\n",
        "        splitted = [] # 分割後の文字列を追加していく\n",
        "        position = 0\n",
        "        for entity in entities:\n",
        "            start = entity['span'][0]\n",
        "            end = entity['span'][1]\n",
        "            label = entity['type_id']\n",
        "            splitted.append({'text':text[position:start], 'label':0})\n",
        "            splitted.append({'text':text[start:end], 'label':label})\n",
        "            position = end\n",
        "        splitted.append({'text': text[position:], 'label':0})\n",
        "        splitted = [ s for s in splitted if s['text'] ]\n",
        "\n",
        "        # 分割されたそれぞれの文章をトークン化し、ラベルをつける。\n",
        "        tokens = [] # トークンを追加していく\n",
        "        labels = [] # ラベルを追加していく\n",
        "        for s in splitted:\n",
        "            tokens_splitted = self.tokenize(s['text'])\n",
        "            label = s['label']\n",
        "            if label > 0: # 固有表現\n",
        "                # まずトークン全てにI-タグを付与\n",
        "                labels_splitted =  \\\n",
        "                    [ label + self.num_entity_type ] * len(tokens_splitted)\n",
        "                # 先頭のトークンをB-タグにする\n",
        "                labels_splitted[0] = label\n",
        "            else: # それ以外\n",
        "                labels_splitted =  [0] * len(tokens_splitted)\n",
        "\n",
        "            tokens.extend(tokens_splitted)\n",
        "            labels.extend(labels_splitted)\n",
        "\n",
        "        # 符号化を行いBERTに入力できる形式にする。\n",
        "        input_ids = self.convert_tokens_to_ids(tokens)\n",
        "        encoding = self.prepare_for_model(\n",
        "            input_ids,\n",
        "            max_length=max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        # ラベルに特殊トークンを追加\n",
        "        labels = [0] + labels[:max_length-2] + [0]\n",
        "        labels = labels + [0]*( max_length - len(labels) )\n",
        "        encoding['labels'] = labels\n",
        "\n",
        "        return encoding\n",
        "\n",
        "    def encode_plus_untagged(\n",
        "        self, text, max_length=None, return_tensors=None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        文章をトークン化し、それぞれのトークンの文章中の位置も特定しておく。\n",
        "        IO法のトークナイザのencode_plus_untaggedと同じ\n",
        "        \"\"\"\n",
        "        # 文章のトークン化を行い、\n",
        "        # それぞれのトークンと文章中の文字列を対応づける。\n",
        "        tokens = [] # トークンを追加していく。\n",
        "        tokens_original = [] # トークンに対応する文章中の文字列を追加していく。\n",
        "        words = self.word_tokenizer.tokenize(text) # MeCabで単語に分割\n",
        "        for word in words:\n",
        "            # 単語をサブワードに分割\n",
        "            tokens_word = self.subword_tokenizer.tokenize(word)\n",
        "            tokens.extend(tokens_word)\n",
        "            if tokens_word[0] == '[UNK]': # 未知語への対応\n",
        "                tokens_original.append(word)\n",
        "            else:\n",
        "                tokens_original.extend([\n",
        "                    token.replace('##','') for token in tokens_word\n",
        "                ])\n",
        "\n",
        "        # 各トークンの文章中での位置を調べる。（空白の位置を考慮する）\n",
        "        position = 0\n",
        "        spans = [] # トークンの位置を追加していく。\n",
        "        for token in tokens_original:\n",
        "            l = len(token)\n",
        "            while 1:\n",
        "                if token != text[position:position+l]:\n",
        "                    position += 1\n",
        "                else:\n",
        "                    spans.append([position, position+l])\n",
        "                    position += l\n",
        "                    break\n",
        "\n",
        "        # 符号化を行いBERTに入力できる形式にする。\n",
        "        input_ids = self.convert_tokens_to_ids(tokens)\n",
        "        encoding = self.prepare_for_model(\n",
        "            input_ids,\n",
        "            max_length=max_length,\n",
        "            padding='max_length' if max_length else False,\n",
        "            truncation=True if max_length else False\n",
        "        )\n",
        "        sequence_length = len(encoding['input_ids'])\n",
        "        # 特殊トークン[CLS]に対するダミーのspanを追加。\n",
        "        spans = [[-1, -1]] + spans[:sequence_length-2]\n",
        "        # 特殊トークン[SEP]、[PAD]に対するダミーのspanを追加。\n",
        "        spans = spans + [[-1, -1]] * ( sequence_length - len(spans) )\n",
        "\n",
        "        # 必要に応じてtorch.Tensorにする。\n",
        "        if return_tensors == 'pt':\n",
        "            encoding = { k: torch.tensor([v]) for k, v in encoding.items() }\n",
        "\n",
        "        return encoding, spans\n",
        "\n",
        "    @staticmethod\n",
        "    def Viterbi(scores_bert, num_entity_type, penalty=10000):\n",
        "        \"\"\"\n",
        "        Viterbiアルゴリズムで最適解を求める。\n",
        "        \"\"\"\n",
        "        m = 2*num_entity_type + 1\n",
        "        penalty_matrix = np.zeros([m, m])\n",
        "        for i in range(m):\n",
        "            for j in range(1+num_entity_type, m):\n",
        "                if not ( (i == j) or (i+num_entity_type == j) ):\n",
        "                    penalty_matrix[i,j] = penalty\n",
        "\n",
        "        path = [ [i] for i in range(m) ]\n",
        "        scores_path = scores_bert[0] - penalty_matrix[0,:]\n",
        "        scores_bert = scores_bert[1:]\n",
        "\n",
        "        for scores in scores_bert:\n",
        "            assert len(scores) == 2*num_entity_type + 1\n",
        "            score_matrix = np.array(scores_path).reshape(-1,1) \\\n",
        "                + np.array(scores).reshape(1,-1) \\\n",
        "                - penalty_matrix\n",
        "            scores_path = score_matrix.max(axis=0)\n",
        "            argmax = score_matrix.argmax(axis=0)\n",
        "            path_new = []\n",
        "            for i, idx in enumerate(argmax):\n",
        "                path_new.append( path[idx] + [i] )\n",
        "            path = path_new\n",
        "\n",
        "        labels_optimal = path[np.argmax(scores_path)]\n",
        "        return labels_optimal\n",
        "\n",
        "    def convert_bert_output_to_entities(self, text, scores, spans):\n",
        "        \"\"\"\n",
        "        文章、分類スコア、各トークンの位置から固有表現を得る。\n",
        "        分類スコアはサイズが（系列長、ラベル数）の2次元配列\n",
        "        \"\"\"\n",
        "        assert len(spans) == len(scores)\n",
        "        num_entity_type = self.num_entity_type\n",
        "\n",
        "        # 特殊トークンに対応する部分を取り除く\n",
        "        scores = [score for score, span in zip(scores, spans) if span[0]!=-1]\n",
        "        spans = [span for span in spans if span[0]!=-1]\n",
        "\n",
        "        # Viterbiアルゴリズムでラベルの予測値を決める。\n",
        "        labels = self.Viterbi(scores, num_entity_type)\n",
        "\n",
        "        # 同じラベルが連続するトークンをまとめて、固有表現を抽出する。\n",
        "        entities = []\n",
        "        for label, group \\\n",
        "            in itertools.groupby(enumerate(labels), key=lambda x: x[1]):\n",
        "\n",
        "            group = list(group)\n",
        "            start = spans[group[0][0]][0]\n",
        "            end = spans[group[-1][0]][1]\n",
        "\n",
        "            if label != 0: # 固有表現であれば\n",
        "                if 1 <= label <= num_entity_type:\n",
        "                     # ラベルが`B-`ならば、新しいentityを追加\n",
        "                    entity = {\n",
        "                        \"name\": text[start:end],\n",
        "                        \"span\": [start, end],\n",
        "                        \"type_id\": label\n",
        "                    }\n",
        "                    entities.append(entity)\n",
        "                else:\n",
        "                    # ラベルが`I-`ならば、直近のentityを更新\n",
        "                    entity['span'][1] = end\n",
        "                    entity['name'] = text[entity['span'][0]:entity['span'][1]]\n",
        "\n",
        "        return entities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvyVJCgH4Z6M"
      },
      "source": [
        "# 8-22\n",
        "# トークナイザのロード\n",
        "# 固有表現のカテゴリーの数`num_entity_type`を入力に入れる必要がある。\n",
        "tokenizer = NER_tokenizer_BIO.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_entity_type=8\n",
        ")\n",
        "\n",
        "# データセットの作成\n",
        "max_length = 128\n",
        "dataset_train_for_loader = create_dataset(\n",
        "    tokenizer, dataset_train, max_length\n",
        ")\n",
        "dataset_val_for_loader = create_dataset(\n",
        "    tokenizer, dataset_val, max_length\n",
        ")\n",
        "\n",
        "# データローダの作成\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train_for_loader, batch_size=32, shuffle=True\n",
        ")\n",
        "dataloader_val = DataLoader(dataset_val_for_loader, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ykfw0rCA4Z9N"
      },
      "source": [
        "# 8-23\n",
        "\n",
        "# ファインチューニング\n",
        "checkpoint = pl.callbacks.ModelCheckpoint(\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_top_k=1,\n",
        "    save_weights_only=True,\n",
        "    dirpath='model_BIO/'\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    gpus=1,\n",
        "    max_epochs=5,\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "\n",
        "# PyTorch Lightningのモデルのロード\n",
        "num_entity_type = 8\n",
        "num_labels = 2*num_entity_type+1\n",
        "model = BertForTokenClassification_pl(\n",
        "    MODEL_NAME, num_labels=num_labels, lr=1e-5\n",
        ")\n",
        "\n",
        "# ファインチューニング\n",
        "trainer.fit(model, dataloader_train, dataloader_val)\n",
        "best_model_path = checkpoint.best_model_path\n",
        "\n",
        "# 性能評価\n",
        "model = BertForTokenClassification_pl.load_from_checkpoint(\n",
        "    best_model_path\n",
        ")\n",
        "bert_tc = model.bert_tc.cuda()\n",
        "\n",
        "entities_list = [] # 正解の固有表現を追加していく\n",
        "entities_predicted_list = [] # 抽出された固有表現を追加していく\n",
        "for sample in tqdm(dataset_test):\n",
        "    text = sample['text']\n",
        "    encoding, spans = tokenizer.encode_plus_untagged(\n",
        "        text, return_tensors='pt'\n",
        "    )\n",
        "    encoding = { k: v.cuda() for k, v in encoding.items() }\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = bert_tc(**encoding)\n",
        "        scores = output.logits\n",
        "        scores = scores[0].cpu().numpy().tolist()\n",
        "\n",
        "    # 分類スコアを固有表現に変換する\n",
        "    entities_predicted = tokenizer.convert_bert_output_to_entities(\n",
        "        text, scores, spans\n",
        "    )\n",
        "\n",
        "    entities_list.append(sample['entities'])\n",
        "    entities_predicted_list.append( entities_predicted )\n",
        "\n",
        "print(evaluate_model(entities_list, entities_predicted_list))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}